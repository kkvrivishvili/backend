# backend/server-llama/docker-compose.scale.yml
version: '3.8'

services:
  embeddings-service:
    build:
      context: .
      dockerfile: embedding-service/Dockerfile
    ports:
      - "8001-8010:8001"  # Rango de puertos para múltiples instancias
    env_file:
      - ./.env
    depends_on:
      - redis
    deploy:
      replicas: 2  # Iniciar 2 instancias
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    networks:
      - llama-net

  ingestion-service:
    build:
      context: .
      dockerfile: ingestion-service/Dockerfile
    ports:
      - "8000:8000"
    env_file:
      - ./.env
    depends_on:
      - redis
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    networks:
      - llama-net

  query-service:
    build:
      context: .
      dockerfile: query-service/Dockerfile
    ports:
      - "8002-8005:8002"  # Rango de puertos para múltiples instancias
    env_file:
      - ./.env
    depends_on:
      - redis
    deploy:
      replicas: 2  # Iniciar 2 instancias
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    networks:
      - llama-net

  agent-service:
    build:
      context: .
      dockerfile: agent-service/Dockerfile
    ports:
      - "8003:8003"
    env_file:
      - ./.env
    depends_on:
      - redis
    deploy:
      replicas: 1
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
    networks:
      - llama-net

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
    volumes:
      - ./nginx.conf:/etc/nginx/conf.d/default.conf:ro
    depends_on:
      - embeddings-service
      - ingestion-service
      - query-service
      - agent-service
    networks:
      - llama-net

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    command: redis-server --save 60 1 --loglevel warning
    volumes:
      - redis-data:/data
    networks:
      - llama-net

networks:
  llama-net:
    driver: bridge

volumes:
  redis-data: